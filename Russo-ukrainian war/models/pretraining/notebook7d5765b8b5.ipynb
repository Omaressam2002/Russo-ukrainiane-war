{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e64bf0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-16T20:03:41.891973Z",
     "iopub.status.busy": "2024-05-16T20:03:41.891308Z",
     "iopub.status.idle": "2024-05-16T20:03:42.626776Z",
     "shell.execute_reply": "2024-05-16T20:03:42.625782Z"
    },
    "papermill": {
     "duration": 0.750054,
     "end_time": "2024-05-16T20:03:42.629026",
     "exception": false,
     "start_time": "2024-05-16T20:03:41.878972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tweets-sg-100/tweets_sg_100.trainables.syn1neg.npy\n",
      "/kaggle/input/tweets-sg-100/tweets_sg_100\n",
      "/kaggle/input/tweets-sg-100/tweets_sg_100.wv.vectors.npy\n",
      "/kaggle/input/normal22/keras/v1/1/config.json\n",
      "/kaggle/input/normal22/keras/v1/1/metadata.json\n",
      "/kaggle/input/normal22/keras/v1/1/model.weights.h5\n",
      "/kaggle/input/normal/keras/normal/1/sup_tweets200k_v2.h5\n",
      "/kaggle/input/partiality-scores/labeled.csv\n",
      "/kaggle/input/partiality-scores/label.csv\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-2.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-3.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-4.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-8.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-5.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-6.keras\n",
      "/kaggle/input/best_weights/keras/best_best/1/best_weights-9.keras\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443b96fb",
   "metadata": {
    "_kg_hide-input": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-16T20:03:42.654177Z",
     "iopub.status.busy": "2024-05-16T20:03:42.653697Z",
     "iopub.status.idle": "2024-05-16T20:04:33.943478Z",
     "shell.execute_reply": "2024-05-16T20:04:33.942481Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 51.305029,
     "end_time": "2024-05-16T20:04:33.945880",
     "exception": false,
     "start_time": "2024-05-16T20:03:42.640851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.4.0\r\n",
      "  Downloading gensim-3.4.0.tar.gz (22.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.10/site-packages (from gensim==3.4.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from gensim==3.4.0) (1.11.4)\r\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from gensim==3.4.0) (1.16.0)\r\n",
      "Requirement already satisfied: smart_open>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from gensim==3.4.0) (6.4.0)\r\n",
      "Building wheels for collected packages: gensim\r\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.4.0-cp310-cp310-linux_x86_64.whl size=22474592 sha256=dc67b0b4741d1c2037a6cbd2eef874ac2526d1de682fd13cbffe97c72988b431\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/9c/3a/80d40a7717710eaa93a73480bd8ec464c77f45c07491987ed0\r\n",
      "Successfully built gensim\r\n",
      "Installing collected packages: gensim\r\n",
      "  Attempting uninstall: gensim\r\n",
      "    Found existing installation: gensim 4.3.2\r\n",
      "    Uninstalling gensim-4.3.2:\r\n",
      "      Successfully uninstalled gensim-4.3.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "scattertext 0.1.19 requires gensim>=4.0.0, but you have gensim 3.4.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed gensim-3.4.0\r\n",
      "Collecting smart_open==1.9.0\r\n",
      "  Downloading smart_open-1.9.0.tar.gz (70 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting boto>=2.32 (from smart_open==1.9.0)\r\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from smart_open==1.9.0) (2.31.0)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from smart_open==1.9.0) (1.26.100)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3->smart_open==1.9.0)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->smart_open==1.9.0) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->smart_open==1.9.0) (0.6.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->smart_open==1.9.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->smart_open==1.9.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->smart_open==1.9.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->smart_open==1.9.0) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->smart_open==1.9.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->smart_open==1.9.0) (1.16.0)\r\n",
      "Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: smart_open\r\n",
      "  Building wheel for smart_open (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for smart_open: filename=smart_open-1.9.0-py3-none-any.whl size=73090 sha256=3d15728edd6c69984e843919cbdc8e00849a34a68d816a517315e9ed50f5669a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4d/dc/d3/830c141138da910baa0318d786130f4596fc13a37b663967cf\r\n",
      "Successfully built smart_open\r\n",
      "Installing collected packages: boto, botocore, smart_open\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.34.69\r\n",
      "    Uninstalling botocore-1.34.69:\r\n",
      "      Successfully uninstalled botocore-1.34.69\r\n",
      "  Attempting uninstall: smart_open\r\n",
      "    Found existing installation: smart-open 6.4.0\r\n",
      "    Uninstalling smart-open-6.4.0:\r\n",
      "      Successfully uninstalled smart-open-6.4.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.29.165 which is incompatible.\r\n",
      "pathy 0.10.3 requires smart-open<7.0.0,>=5.2.1, but you have smart-open 1.9.0 which is incompatible.\r\n",
      "scattertext 0.1.19 requires gensim>=4.0.0, but you have gensim 3.4.0 which is incompatible.\r\n",
      "spacy 3.7.3 requires smart-open<7.0.0,>=5.2.1, but you have smart-open 1.9.0 which is incompatible.\r\n",
      "weasel 0.3.4 requires smart-open<7.0.0,>=5.2.1, but you have smart-open 1.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed boto-2.49.0 botocore-1.29.165 smart_open-1.9.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.4.0\n",
    "!pip install smart_open==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ea0de",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-16T07:46:53.544441Z",
     "iopub.status.busy": "2024-05-16T07:46:53.543742Z",
     "iopub.status.idle": "2024-05-16T07:46:56.442814Z",
     "shell.execute_reply": "2024-05-16T07:46:56.441773Z",
     "shell.execute_reply.started": "2024-05-16T07:46:53.544407Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015053,
     "end_time": "2024-05-16T20:04:33.976518",
     "exception": false,
     "start_time": "2024-05-16T20:04:33.961465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddfe7aa9",
   "metadata": {
    "papermill": {
     "duration": 0.014927,
     "end_time": "2024-05-16T20:04:34.007662",
     "exception": false,
     "start_time": "2024-05-16T20:04:33.992735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Pretraining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c399807b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T20:04:34.040137Z",
     "iopub.status.busy": "2024-05-16T20:04:34.039772Z",
     "iopub.status.idle": "2024-05-16T20:04:36.569343Z",
     "shell.execute_reply": "2024-05-16T20:04:36.567995Z"
    },
    "papermill": {
     "duration": 2.547892,
     "end_time": "2024-05-16T20:04:36.571119",
     "exception": true,
     "start_time": "2024-05-16T20:04:34.023227",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mapping' from 'collections' (/opt/conda/lib/python3.10/collections/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/partiality-scores/label.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This package contains interfaces and functionality to compute pair-wise document similarities within a corpus\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mof documents.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.4.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/corpora/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvmlightcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SvmLightCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlowcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LowCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdictionary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashdictionary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HashDictionary  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwikicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WikiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/corpora/dictionary.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"This module implements the concept of Dictionary -- a mapping between words and their integer ids.\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m with_statement\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mapping, defaultdict\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Mapping' from 'collections' (/opt/conda/lib/python3.10/collections/__init__.py)"
     ]
    }
   ],
   "source": [
    "from nltk.stem.isri import ISRIStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/partiality-scores/label.csv\")\n",
    "sentences = df[\"preprocessed tweets\"].astype(str)\n",
    "target_sentences = df[\"preprocessed tweets\"].astype(str)\n",
    "\n",
    "tweets_sg_100 = '/kaggle/input/tweets-sg-100/tweets_sg_100'\n",
    "sg_model = gensim.models.Word2Vec.load(tweets_sg_100)\n",
    "stemmer = ISRIStemmer()\n",
    "\n",
    "# ANALYZE HASHTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00808f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:05:42.305339Z",
     "iopub.status.busy": "2024-05-16T16:05:42.304386Z",
     "iopub.status.idle": "2024-05-16T16:05:42.353635Z",
     "shell.execute_reply": "2024-05-16T16:05:42.352365Z",
     "shell.execute_reply.started": "2024-05-16T16:05:42.305300Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from snowballstemmer import stemmer\n",
    "ar_stemmer = stemmer(\"arabic\")\n",
    "def clean_str(text):\n",
    "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\n",
    "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ',' ! ']\n",
    "    \n",
    "    #remove tashkeel\n",
    "    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(p_tashkeel,\"\", text)\n",
    "    \n",
    "    #remove longation\n",
    "    p_longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = re.sub(p_longation, subst, text)\n",
    "    \n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "    \n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "\n",
    "    words = text.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = ar_stemmer.stemWord(words[i])\n",
    "\n",
    "        \n",
    "       \n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85071a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-15T16:34:44.148797Z",
     "iopub.status.idle": "2024-05-15T16:34:44.149149Z",
     "shell.execute_reply": "2024-05-15T16:34:44.148984Z",
     "shell.execute_reply.started": "2024-05-15T16:34:44.148971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = sentences.apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7af72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:36:51.406225Z",
     "iopub.status.busy": "2024-05-16T17:36:51.405425Z",
     "iopub.status.idle": "2024-05-16T17:36:51.413897Z",
     "shell.execute_reply": "2024-05-16T17:36:51.412977Z",
     "shell.execute_reply.started": "2024-05-16T17:36:51.406192Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "russia = ['روسي','روس','روسيه','لروسي','والروس','ياروسي','روسی','موسك'] # 'روسيا'\n",
    "belarus = ['يلاروسي','يلاروس','بيلاروس','بيلاروسيه','لبيلاروسي','والبيلاروس'] # 'بيلاروسيا'\n",
    "ukr = ['اوكران','واوكراني','اوكر','لاوكراني','ناتو'] # 'اوكرانيا'\n",
    "russian_hashtags = ['جيشالروس','قواتالروسيه','روسياليوم','روسياتنتصر','خارجيهالروسيه','عمليهالعسكريهالروسيه'] # روسيا\n",
    "ukr_russian_hashtags = ['حربالروسيهالاوكرانيه','روسياوكراني','اوكرانياروسي','غزوالروسيلاوكرانيا','روسياواوكراني'] # 'حرب'\n",
    "ukr_hashtags = ['روسياتغزواوكراني','روسياتكذب','روسيالص','روسياوالص','روسيامجرم','مجدلاوكرانيا','مخابراتالاوكرانيه'] # 'اوكرانيا'\n",
    "zelensky = ['زيلينسك','زلينسك'] # 'اوباما'\n",
    "putin = ['بوتن','وتن','پوتن','وتين','بوتين','پوتين'] #'بوتين'\n",
    "war = ['حربالعالميه', 'حربالعالميهالثالثه','عسكريه'] # 'حرب'\n",
    "egypt = ['مصر','مصريه','لمصر'] # 'عربي'\n",
    "us = ['وامريك','الولاياتالمتحده','الولاياتالمتحده','الولاياتالمتحدهالامريكيه','البريطانيا','والولايا'] # 'امريكا'\n",
    "gb = ['ريطاني'] # \"بريطانيا\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611322c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:36:53.833484Z",
     "iopub.status.busy": "2024-05-16T17:36:53.832599Z",
     "iopub.status.idle": "2024-05-16T17:36:53.840262Z",
     "shell.execute_reply": "2024-05-16T17:36:53.839279Z",
     "shell.execute_reply.started": "2024-05-16T17:36:53.833454Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "russia.extend(russian_hashtags)\n",
    "ukr.extend(ukr_hashtags)\n",
    "war.extend(ukr_russian_hashtags)\n",
    "\n",
    "added_words = []\n",
    "added_words.extend(russia)\n",
    "added_words.extend(ukr)\n",
    "added_words.extend(war)\n",
    "added_words.extend(putin)\n",
    "added_words.extend(zelensky)\n",
    "added_words.extend(egypt)\n",
    "added_words.extend(us)\n",
    "added_words.extend(gb)\n",
    "added_words = set(added_words)\n",
    "russia = set(russia)\n",
    "ukr = set(ukr)\n",
    "war = set(war)\n",
    "putin = set(putin)\n",
    "zelensky = set(zelensky)\n",
    "egypt = set(egypt)\n",
    "us = set(us)\n",
    "gb = set(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f8eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:36:55.836358Z",
     "iopub.status.busy": "2024-05-16T17:36:55.835474Z",
     "iopub.status.idle": "2024-05-16T17:36:58.839290Z",
     "shell.execute_reply": "2024-05-16T17:36:58.837976Z",
     "shell.execute_reply.started": "2024-05-16T17:36:55.836324Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add words that donot exist to wv\n",
    "# russia 'روسيا', ukr 'اوكرانيا', war 'حرب' , putin 'بوتين', zelensky 'اوباما', belarus 'بيلاروسيا' , egypt 'قطر', us 'امريكا', gb \"بريطانيا\"\n",
    "for word in russia:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['روسيا'])\n",
    "for word in ukr:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['اوكرانيا'])\n",
    "for word in war:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['حرب'])\n",
    "for word in putin:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['بوتين'])\n",
    "for word in zelensky:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['اوباما'])\n",
    "for word in belarus:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['بيلاروسيا'])\n",
    "for word in egypt:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['قطر'])   \n",
    "for word in us:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['امريكا']) \n",
    "for word in gb:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv[\"بريطانيا\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c1724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:37:04.726909Z",
     "iopub.status.busy": "2024-05-16T17:37:04.726537Z",
     "iopub.status.idle": "2024-05-16T17:37:06.819678Z",
     "shell.execute_reply": "2024-05-16T17:37:06.818752Z",
     "shell.execute_reply.started": "2024-05-16T17:37:04.726880Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = max([len(sentence.split()) for sentence in sentences])\n",
    "num_encoder_tokens = max_len\n",
    "num_decoder_tokens = max_len\n",
    "print(max_len)\n",
    "latent_dim = 64\n",
    "plt.hist([ len(sentence.split()) for sentence in sentences] , bins=range(0,300,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39500ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:06:02.621589Z",
     "iopub.status.busy": "2024-05-16T16:06:02.620465Z",
     "iopub.status.idle": "2024-05-16T16:06:03.260587Z",
     "shell.execute_reply": "2024-05-16T16:06:03.259576Z",
     "shell.execute_reply.started": "2024-05-16T16:06:02.621548Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce9277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:37:28.193133Z",
     "iopub.status.busy": "2024-05-16T17:37:28.192751Z",
     "iopub.status.idle": "2024-05-16T17:37:57.292828Z",
     "shell.execute_reply": "2024-05-16T17:37:57.291767Z",
     "shell.execute_reply.started": "2024-05-16T17:37:28.193107Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex_length = 100000\n",
    "max_len = max([ len(sentence.split()) for sentence in sentences ])\n",
    "encoder_input_data = np.zeros([ex_length,max_len+5,100])\n",
    "decoder_output_data = np.zeros([ex_length,max_len+5,100])\n",
    "decoder_input_data = np.zeros([ex_length,max_len+5,100])\n",
    "\n",
    "for ex in range(100000):\n",
    "    words = sentences[ex].split()\n",
    "    position = 0\n",
    "    for word in words:\n",
    "        if word in sg_model.wv:\n",
    "            encoder_input_data[ex,position,:] = sg_model.wv[word]\n",
    "            decoder_input_data[ex,position+1,:] = sg_model.wv[word] \n",
    "            decoder_output_data[ex,position,:] = sg_model.wv[word] \n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c337b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:38:27.363947Z",
     "iopub.status.busy": "2024-05-16T17:38:27.363089Z",
     "iopub.status.idle": "2024-05-16T17:38:35.387172Z",
     "shell.execute_reply": "2024-05-16T17:38:35.386245Z",
     "shell.execute_reply.started": "2024-05-16T17:38:27.363905Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Dense, Flatten\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, 100),name='e_inp') \n",
    "decoder_inputs = Input(shape=(None, 100),name='d_inp')\n",
    "encoder = Bidirectional(LSTM(64, return_state=True),name='enc')\n",
    "encoder_outputs, hf, hb, cf, cb = encoder(encoder_inputs)\n",
    "encoder_states = [hf, hb, cf, cb]\n",
    "decoder_lstm = Bidirectional(LSTM(64, return_sequences=True, return_state=True),name='dec')\n",
    "decoder_outputs, dhf, dhb, dcf, dcb = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = Dense(100,name=\"dense_1\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f2f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T09:51:07.255301Z",
     "iopub.status.busy": "2024-05-16T09:51:07.254546Z",
     "iopub.status.idle": "2024-05-16T09:51:07.317325Z",
     "shell.execute_reply": "2024-05-16T09:51:07.316565Z",
     "shell.execute_reply.started": "2024-05-16T09:51:07.255271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.saving import load_model\n",
    "model = load_model(\"pretrainig_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709f7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:38:40.724344Z",
     "iopub.status.busy": "2024-05-16T17:38:40.723100Z",
     "iopub.status.idle": "2024-05-16T17:38:40.768486Z",
     "shell.execute_reply": "2024-05-16T17:38:40.767738Z",
     "shell.execute_reply.started": "2024-05-16T17:38:40.724301Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"pre_model_bilstm.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abd8e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:17:06.411223Z",
     "iopub.status.busy": "2024-05-16T16:17:06.410174Z",
     "iopub.status.idle": "2024-05-16T16:29:25.723839Z",
     "shell.execute_reply": "2024-05-16T16:29:25.722783Z",
     "shell.execute_reply.started": "2024-05-16T16:17:06.411187Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.losses import CosineSimilarity, MeanSquaredError\n",
    "cs_loss = CosineSimilarity(axis=-1, reduction=\"sum_over_batch_size\", name=\"cosine_similarity\")\n",
    "model.compile(optimizer='adam',loss=cs_loss ,metrics=['acc'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6cd75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:30:12.379253Z",
     "iopub.status.busy": "2024-05-16T16:30:12.378903Z",
     "iopub.status.idle": "2024-05-16T16:30:12.454017Z",
     "shell.execute_reply": "2024-05-16T16:30:12.453200Z",
     "shell.execute_reply.started": "2024-05-16T16:30:12.379224Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"pre_model_bilstm.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9dff6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# **Partiality** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745bbbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:38:48.774578Z",
     "iopub.status.busy": "2024-05-16T17:38:48.773692Z",
     "iopub.status.idle": "2024-05-16T17:38:51.794390Z",
     "shell.execute_reply": "2024-05-16T17:38:51.793469Z",
     "shell.execute_reply.started": "2024-05-16T17:38:48.774545Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/partiality-scores/labeled.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9d133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:39:02.200174Z",
     "iopub.status.busy": "2024-05-16T17:39:02.199814Z",
     "iopub.status.idle": "2024-05-16T17:39:02.216778Z",
     "shell.execute_reply": "2024-05-16T17:39:02.215774Z",
     "shell.execute_reply.started": "2024-05-16T17:39:02.200149Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = df['preprocessed tweets'].astype(str)\n",
    "labels = df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7a6ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:39:04.868980Z",
     "iopub.status.busy": "2024-05-16T17:39:04.868115Z",
     "iopub.status.idle": "2024-05-16T17:39:04.971054Z",
     "shell.execute_reply": "2024-05-16T17:39:04.970035Z",
     "shell.execute_reply.started": "2024-05-16T17:39:04.868948Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_train = list(features[:200000])\n",
    "features_test = list(features[20000:])\n",
    "labels_train = list(labels[:200000])\n",
    "labels_test = list(labels[200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0e174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:30:49.574255Z",
     "iopub.status.busy": "2024-05-16T16:30:49.573925Z",
     "iopub.status.idle": "2024-05-16T16:31:03.959331Z",
     "shell.execute_reply": "2024-05-16T16:31:03.958544Z",
     "shell.execute_reply.started": "2024-05-16T16:30:49.574230Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem.isri import ISRIStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "\n",
    "tweets_sg_100 = '/kaggle/input/tweets-sg-100/tweets_sg_100'\n",
    "sg_model = gensim.models.Word2Vec.load(tweets_sg_100)\n",
    "\n",
    "# ANALYZE HASHTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07da574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:31:08.386292Z",
     "iopub.status.busy": "2024-05-16T16:31:08.385531Z",
     "iopub.status.idle": "2024-05-16T16:31:11.392493Z",
     "shell.execute_reply": "2024-05-16T16:31:11.391476Z",
     "shell.execute_reply.started": "2024-05-16T16:31:08.386258Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# important words not recognized by the embedder \n",
    "russia = ['روسي','روس','روسيه','لروسي','والروس','ياروسي','روسی','موسك'] # 'روسيا'\n",
    "belarus = ['يلاروسي','يلاروس','بيلاروس','بيلاروسيه','لبيلاروسي','والبيلاروس'] # 'بيلاروسيا'\n",
    "ukr = ['اوكران','واوكراني','اوكر','لاوكراني','ناتو'] # 'اوكرانيا'\n",
    "russian_hashtags = ['جيشالروس','قواتالروسيه','روسياليوم','روسياتنتصر','خارجيهالروسيه','عمليهالعسكريهالروسيه'] # روسيا\n",
    "ukr_russian_hashtags = ['حربالروسيهالاوكرانيه','روسياوكراني','اوكرانياروسي','غزوالروسيلاوكرانيا','روسياواوكراني'] # 'حرب'\n",
    "ukr_hashtags = ['روسياتغزواوكراني','روسياتكذب','روسيالص','روسياوالص','روسيامجرم','مجدلاوكرانيا','مخابراتالاوكرانيه'] # 'اوكرانيا'\n",
    "zelensky = ['زيلينسك','زلينسك'] # 'اوباما'\n",
    "putin = ['بوتن','وتن','پوتن','وتين','بوتين','پوتين'] #'بوتين'\n",
    "war = ['حربالعالميه', 'حربالعالميهالثالثه','عسكريه'] # 'حرب'\n",
    "egypt = ['مصر','مصريه','لمصر'] # 'عربي'\n",
    "us = ['وامريك','الولاياتالمتحده','الولاياتالمتحده','الولاياتالمتحدهالامريكيه','البريطانيا','والولايا','امريك'] # 'امريكا'\n",
    "gb = ['ريطاني'] # \"بريطانيا\"\n",
    "\n",
    "\n",
    "russia.extend(russian_hashtags)\n",
    "ukr.extend(ukr_hashtags)\n",
    "war.extend(ukr_russian_hashtags)\n",
    "\n",
    "added_words = []\n",
    "added_words.extend(russia)\n",
    "added_words.extend(ukr)\n",
    "added_words.extend(war)\n",
    "added_words.extend(putin)\n",
    "added_words.extend(zelensky)\n",
    "added_words.extend(egypt)\n",
    "added_words.extend(us)\n",
    "added_words.extend(gb)\n",
    "added_words = set(added_words)\n",
    "russia = set(russia)\n",
    "ukr = set(ukr)\n",
    "war = set(war)\n",
    "putin = set(putin)\n",
    "zelensky = set(zelensky)\n",
    "egypt = set(egypt)\n",
    "us = set(us)\n",
    "gb = set(gb)\n",
    "\n",
    "# add words that donot exist to wv\n",
    "# russia 'روسيا', ukr 'اوكرانيا', war 'حرب' , putin 'بوتين', zelensky 'اوباما', belarus 'بيلاروسيا' , egypt 'قطر', us 'امريكا', gb \"بريطانيا\"\n",
    "# for each set of words assign them to a vector of a similar word to them.\n",
    "for word in russia:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['روسيا'])\n",
    "for word in ukr:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['اوكرانيا'])\n",
    "for word in war:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['حرب'])\n",
    "for word in putin:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['بوتين'])\n",
    "for word in zelensky:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['اوباما'])\n",
    "for word in belarus:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['بيلاروسيا'])\n",
    "for word in egypt:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['قطر'])   \n",
    "for word in us:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv['امريكا']) \n",
    "for word in gb:\n",
    "    sg_model.wv.add_vector(word,sg_model.wv[\"بريطانيا\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8e21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T18:32:58.616740Z",
     "iopub.status.busy": "2024-05-16T18:32:58.616048Z",
     "iopub.status.idle": "2024-05-16T18:32:58.847273Z",
     "shell.execute_reply": "2024-05-16T18:32:58.846172Z",
     "shell.execute_reply.started": "2024-05-16T18:32:58.616687Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many tweets \n",
    "ex_length = 200000\n",
    "# how many words per tweet : pad with zeros if words are less than max_len\n",
    "max_len = 64\n",
    "# each word is represented in a vector of size 100 \n",
    "word_vector = 100\n",
    "X_train = np.zeros([ex_length,max_len,word_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db31d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T18:33:08.355266Z",
     "iopub.status.busy": "2024-05-16T18:33:08.354604Z",
     "iopub.status.idle": "2024-05-16T18:33:32.719308Z",
     "shell.execute_reply": "2024-05-16T18:33:32.718169Z",
     "shell.execute_reply.started": "2024-05-16T18:33:08.355235Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ex in range(200000):\n",
    "    words = features[ex].split()\n",
    "    position = 0\n",
    "    for word in words:\n",
    "        if word in sg_model.wv:\n",
    "            X_train[ex,position,:] = sg_model.wv[word]\n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71b7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T18:33:59.829834Z",
     "iopub.status.busy": "2024-05-16T18:33:59.828784Z",
     "iopub.status.idle": "2024-05-16T18:33:59.946858Z",
     "shell.execute_reply": "2024-05-16T18:33:59.945766Z",
     "shell.execute_reply.started": "2024-05-16T18:33:59.829798Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Map labels to integer values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(labels_train[:200000])\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b2a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:42:42.546479Z",
     "iopub.status.busy": "2024-05-16T17:42:42.545532Z",
     "iopub.status.idle": "2024-05-16T17:42:42.606818Z",
     "shell.execute_reply": "2024-05-16T17:42:42.605873Z",
     "shell.execute_reply.started": "2024-05-16T17:42:42.546430Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = model.get_layer('enc')\n",
    "config = encoder.get_config()\n",
    "config['layer']['config']['return_state'] = False\n",
    "config['layer']['config']['return_sequences'] = True\n",
    "\n",
    "encoder_layer_new = Bidirectional(LSTM.from_config(config['layer']['config']), name='enc')\n",
    "\n",
    "# Get the weights of the original encoder layer and set them to the new layer\n",
    "encoder_layer_new.build((None,None,100))\n",
    "encoder_layer_new.set_weights(encoder.get_weights())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcdd0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T19:19:34.124123Z",
     "iopub.status.busy": "2024-05-16T19:19:34.123731Z",
     "iopub.status.idle": "2024-05-16T19:19:34.165222Z",
     "shell.execute_reply": "2024-05-16T19:19:34.164327Z",
     "shell.execute_reply.started": "2024-05-16T19:19:34.124093Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "# Add Bidirectional LSTM layers\n",
    "model.add(encoder_layer_new)\n",
    "model.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "\n",
    "# Add Dense layer\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "\n",
    "# Add Softmax layer\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "loss= CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction=\"sum_over_batch_size\",\n",
    "    name=\"categorical_crossentropy\",\n",
    ")\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afbca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T19:19:39.650688Z",
     "iopub.status.busy": "2024-05-16T19:19:39.649840Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint filepath with '.keras' extension\n",
    "checkpoint_filepath = 'best_weights.keras'\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                      save_best_only=True,\n",
    "                                      monitor='val_accuracy',\n",
    "                                      mode='max',  # 'max' for accuracy\n",
    "                                      verbose=1)\n",
    "\n",
    "# Train the model with ModelCheckpoint callback\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    epochs=1,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[checkpoint_callback],shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2738d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:45:53.753593Z",
     "iopub.status.busy": "2024-05-16T17:45:53.753200Z",
     "iopub.status.idle": "2024-05-16T17:45:53.763912Z",
     "shell.execute_reply": "2024-05-16T17:45:53.762941Z",
     "shell.execute_reply.started": "2024-05-16T17:45:53.753563Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = list(sentences[200000:].astype(str))\n",
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd518d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:46:15.123463Z",
     "iopub.status.busy": "2024-05-16T17:46:15.123063Z",
     "iopub.status.idle": "2024-05-16T17:46:17.399144Z",
     "shell.execute_reply": "2024-05-16T17:46:17.398282Z",
     "shell.execute_reply.started": "2024-05-16T17:46:15.123433Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = list(sentences[200000:].astype(str))\n",
    "ex_length = len(test_set)\n",
    "encoder_input_data = np.zeros([ex_length,64,100])\n",
    "for ex in range(ex_length):\n",
    "    words = test_set[ex].split()\n",
    "    position = 0\n",
    "    for word in words:\n",
    "        if word in sg_model.wv: \n",
    "            encoder_input_data[ex,position,:] = sg_model.wv[word]\n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de2c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:48:18.785164Z",
     "iopub.status.busy": "2024-05-16T17:48:18.784182Z",
     "iopub.status.idle": "2024-05-16T17:48:18.799116Z",
     "shell.execute_reply": "2024-05-16T17:48:18.798310Z",
     "shell.execute_reply.started": "2024-05-16T17:48:18.785132Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_encoded = label_encoder.fit_transform(labels_test)\n",
    "y_test_one_hot = to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dede5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T19:14:56.762612Z",
     "iopub.status.busy": "2024-05-16T19:14:56.761675Z",
     "iopub.status.idle": "2024-05-16T19:15:03.051121Z",
     "shell.execute_reply": "2024-05-16T19:15:03.050108Z",
     "shell.execute_reply.started": "2024-05-16T19:14:56.762579Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss,accuracy = model.evaluate(encoder_input_data,y_test_one_hot)\n",
    "\n",
    "print(f\"Loss :{loss:.4f}\")\n",
    "print(f\"Accuracy :{accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cac87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:51:08.340767Z",
     "iopub.status.busy": "2024-05-16T17:51:08.339849Z",
     "iopub.status.idle": "2024-05-16T17:51:08.692207Z",
     "shell.execute_reply": "2024-05-16T17:51:08.690992Z",
     "shell.execute_reply.started": "2024-05-16T17:51:08.340726Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"post_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b807a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T19:38:55.793276Z",
     "iopub.status.busy": "2024-05-16T19:38:55.792571Z",
     "iopub.status.idle": "2024-05-16T19:38:55.956331Z",
     "shell.execute_reply": "2024-05-16T19:38:55.955254Z",
     "shell.execute_reply.started": "2024-05-16T19:38:55.793242Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/kaggle/input/best_weights/keras/best_best/1/best_weights-9.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32e01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T19:59:02.300955Z",
     "iopub.status.busy": "2024-05-16T19:59:02.300163Z",
     "iopub.status.idle": "2024-05-16T19:59:08.545127Z",
     "shell.execute_reply": "2024-05-16T19:59:08.544118Z",
     "shell.execute_reply.started": "2024-05-16T19:59:02.300920Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss,accuracy = model.evaluate(encoder_input_data,y_test_one_hot)\n",
    "\n",
    "print(f\"Loss :{loss:.4f}\")\n",
    "print(f\"Accuracy :{accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061c3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T19:59:00.107306Z",
     "iopub.status.busy": "2024-05-16T19:59:00.106548Z",
     "iopub.status.idle": "2024-05-16T19:59:00.250987Z",
     "shell.execute_reply": "2024-05-16T19:59:00.249932Z",
     "shell.execute_reply.started": "2024-05-16T19:59:00.107273Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/kaggle/input/normal22/keras/v1/1/model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e063aa0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model 4 is the best model\n",
    "# model.weights.h5"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5012023,
     "sourceId": 8419277,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5008857,
     "sourceId": 8428354,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 40902,
     "sourceId": 48925,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 40904,
     "sourceId": 48928,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 40909,
     "sourceId": 48933,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.981547,
   "end_time": "2024-05-16T20:04:37.108811",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T20:03:39.127264",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
